# Интеграция данных Prometheus в Time-Series-Library

Этот документ описывает, как использовать данные из Prometheus для тестирования различных моделей временных рядов.

## Что было сделано

1. **Создан Dataset_Prometheus** - новый класс для загрузки данных из Prometheus
2. **Интегрирован в data_factory** - добавлен тип данных 'prometheus'
3. **Созданы скрипты тестирования** - для автоматического тестирования моделей

## Структура данных

- **Период**: 2025-04-27 18:00:00 - 2025-05-13 11:41:00
- **Количество точек**: 90,600
- **Интервал**: 15 секунд
- **Метрика**: common_delayp90 (90-й перцентиль задержки)
- **Разделение данных**: 70% train / 20% validation / 10% test

## Быстрый старт

### 1. Тестирование одной модели

```bash
# Тестирование TimesNet (по умолчанию)
python test_single_model.py

# Тестирование конкретной модели
python test_single_model.py DLinear
python test_single_model.py Autoformer
python test_single_model.py PatchTST
```

### 2. Тестирование всех моделей

```bash
# Запуск полного тестирования (может занять несколько часов)
python test_prometheus_models.py
```

### 3. Ручной запуск

```bash
python run.py \
    --task_name long_term_forecast \
    --is_training 1 \
    --model_id TimesNet_prometheus \
    --model TimesNet \
    --data prometheus \
    --features S \
    --target common_delayp90 \
    --freq 15s \
    --seq_len 96 \
    --label_len 48 \
    --pred_len 96 \
    --enc_in 1 \
    --dec_in 1 \
    --c_out 1 \
    --train_epochs 10
```

## Доступные модели

Протестированы следующие модели:
- **TimesNet** - современная модель с временными блоками
- **Autoformer** - автокорреляционный трансформер
- **Transformer** - классический трансформер
- **DLinear** - простая линейная модель с декомпозицией
- **NLinear** - нормализованная линейная модель
- **Linear** - базовая линейная модель
- **PatchTST** - трансформер с патчами
- **iTransformer** - инвертированный трансформер
- **Crossformer** - кросс-размерный трансформер
- **FEDformer** - трансформер с Фурье-декомпозицией
- **Informer** - эффективный трансформер

## Параметры модели

### Временные параметры
- `seq_len`: 96 (24 минуты входной последовательности)
- `label_len`: 48 (12 минут стартовых токенов)
- `pred_len`: 96 (24 минуты предсказания)

### Архитектура
- `d_model`: 512 (размерность модели)
- `n_heads`: 8 (количество голов внимания)
- `e_layers`: 2 (слои энкодера)
- `d_layers`: 1 (слои декодера)

### Обучение
- `batch_size`: 32
- `learning_rate`: 0.0001
- `train_epochs`: 10
- `patience`: 3 (early stopping)

## Результаты

После обучения результаты сохраняются в:
- `./checkpoints/` - веса моделей
- Логи обучения выводятся в консоль

## Анализ результатов

Для каждой модели выводятся метрики:
- **MSE** (Mean Squared Error)
- **MAE** (Mean Absolute Error)
- **Время обучения**
- **Время инференса**

## Настройка под свои данные

Чтобы использовать другие данные из Prometheus:

1. Измените параметры в `data_loader.py`:
   ```python
   start_date: str = "ваша_дата_начала"
   end_date: str = "ваша_дата_конца"
   ```

2. Обновите метрику в `METRIC_CFG`:
   ```python
   METRIC_CFG = {
       "your_metric": "your_prometheus_query"
   }
   ```

3. Измените `target` в скриптах тестирования:
   ```python
   'target': 'your_metric_name'
   ```

## Рекомендации

### Для быстрого тестирования:
1. Начните с простых моделей: `Linear`, `DLinear`, `NLinear`
2. Используйте меньше эпох: `--train_epochs 5`

### Для лучшего качества:
1. Увеличьте количество эпох: `--train_epochs 20`
2. Попробуйте разные размеры окон: `--seq_len 192 --pred_len 48`
3. Настройте learning rate: `--learning_rate 0.00005`

### Для больших данных:
1. Увеличьте batch_size: `--batch_size 64`
2. Используйте несколько GPU: `--use_multi_gpu --devices 0,1,2,3`

## Troubleshooting

### Ошибка "Target column not found"
Проверьте, что данные загружены и содержат нужную метрику:
```python
from data_loader import fetch_frame
df = fetch_frame(use_cache=True)
print(df.columns)
```

### Ошибка памяти
Уменьшите batch_size:
```bash
--batch_size 16
```

### Медленное обучение
Используйте GPU:
```bash
--use_gpu True --gpu 0
```

## Следующие шаги

1. **Анализ результатов** - сравните метрики разных моделей
2. **Гиперпараметры** - настройте параметры лучших моделей
3. **Ансамбли** - объедините предсказания нескольких моделей
4. **Продакшн** - разверните лучшую модель для реального использования 